## Минькин Федор,  М05-894а

Возьмем датасет tic-tac-toe, т.е. крестики-нолики.

В качестве датасета был выбран tic-tac-toe (крестики-нолики). В датасете есть 9 фичей, на каждую клетку игрового поля. 

Каждая фича принимает значения "x", "o" - крестик/нолик в поле, либо "b" - отсутствие крестика и нолика. Таргет - победили ли крестики.

В датасете 958 примеров игр: положительных - 626, отрицательных - 332.


В качестве метрик используем Accuracy, Precision, Recall и несколько других, основная - Accuracy.

Для оценки качества разбиваем датасет на 20 фолдов, учимся на всех кроме одного, на нем тестируемся. Итоговое качество метода - усреднение по 10 разбиениям.

В качестве референсных значений посмотрим на стандартные модели sklearn

Изучим, как работает **Logistic Regression**


1. **accuracy**: 0.9548026315789475

2. **f1_score**: 0.6978891382032744

3. **precision**: 0.6958333333333334

4. **recall**: 0.7


Теперь попробуем Catboost с категориальными фичами.

1. **accuracy**: 0.649671052631579

2. **f1_score**: 0.6054329218465744

3. **precision**: 0.5720416666666667

4. **recall**: 0.6623376623376623


Работает ужасно.

**Приступим к FCA модели.**

После долгих попыток перебора моделей, лучшая модель получилась такая:
Для каждой тестовой записи считаем supp = |(g+ /\ g-)+|, и берем две статистики:

* min
* median

Итоговая функция принятия решений:

* min(supp) * median(supp) > 9.27e-05

Такая модель получает 

1. **accuracy**: 0.9655

2. **f1_score**: 0.9756

3. **precision**: 0.9524

4. **recall**: 1.0000

Что сильно лучше бейзлайнов!
